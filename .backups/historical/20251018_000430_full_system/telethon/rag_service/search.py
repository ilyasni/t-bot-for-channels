"""
–°–µ—Ä–≤–∏—Å –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ—Å—Ç–∞–º

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ embeddings
- –§–∏–ª—å—Ç—Ä—ã: channel_id, tags, date range
- Re-ranking —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""
import logging
import sys
import os
from typing import List, Optional, Dict, Any
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from database import SessionLocal
from models import Post, Channel
from vector_db import qdrant_client
from embeddings import embeddings_service
import config

# Observability
try:
    from observability.langfuse_client import langfuse_client
    from observability.metrics import rag_search_duration_seconds, rag_query_errors_total
except ImportError:
    logger = logging.getLogger(__name__)
    logger.warning("‚ö†Ô∏è Observability modules not available")
    langfuse_client = None
    rag_search_duration_seconds = None
    rag_query_errors_total = None

logger = logging.getLogger(__name__)


class SearchService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ—Å—Ç–∞–º"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–∏—Å–∫–∞"""
        self.qdrant = qdrant_client
        self.embeddings = embeddings_service
        logger.info("‚úÖ Search Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def search(
        self,
        query: str,
        user_id: int,
        limit: int = 10,
        channel_id: Optional[int] = None,
        tags: Optional[List[str]] = None,
        date_from: Optional[datetime] = None,
        date_to: Optional[datetime] = None,
        min_score: Optional[float] = None
    ) -> List[Dict[str, Any]]:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ—Å—Ç–∞–º
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            channel_id: –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω–∞–ª—É
            tags: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–≥–∞–º
            date_from: –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ (–æ—Ç)
            date_to: –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ (–¥–æ)
            min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            result = await self.embeddings.generate_embedding(query)
            if not result:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
                if rag_query_errors_total:
                    rag_query_errors_total.labels(error_type='embedding_failed').inc()
                return []
            
            query_vector, provider = result
            logger.info(f"üîç –ü–æ–∏—Å–∫ –¥–ª—è user {user_id}: '{query}' (embedding: {provider})")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º min_score –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
            if min_score is None:
                min_score = config.RAG_MIN_SCORE
            
            # Prometheus metrics: measure Qdrant search latency
            if rag_search_duration_seconds:
                timer = rag_search_duration_seconds.time()
                timer.__enter__()
            else:
                timer = None
            
            # Langfuse tracing
            trace_ctx = langfuse_client.trace_context(
                "rag_vector_search",
                metadata={
                    "user_id": user_id,
                    "query_length": len(query),
                    "limit": limit,
                    "provider": provider
                }
            ) if langfuse_client else None
            
            trace = None
            if trace_ctx:
                trace = trace_ctx.__enter__()
            
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Qdrant
                search_results = await self.qdrant.search(
                    user_id=user_id,
                    query_vector=query_vector,
                    limit=limit,
                    score_threshold=min_score,
                    channel_id=channel_id,
                    tags=tags,
                    date_from=date_from,
                    date_to=date_to
                )
                
                # Update trace with results
                if trace:
                    trace.update(metadata={"results_count": len(search_results) if search_results else 0})
                
            finally:
                if timer:
                    timer.__exit__(None, None, None)
                if trace_ctx:
                    trace_ctx.__exit__(None, None, None)
            
            if not search_results:
                logger.info(f"üì≠ –ü–æ–∏—Å–∫ –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è user {user_id}")
                return []
            
            # –û–±–æ–≥–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î
            enriched_results = await self._enrich_search_results(search_results)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º date —Ñ–∏–ª—å—Ç—Ä –ø–æ—Å–ª–µ –æ–±–æ–≥–∞—â–µ–Ω–∏—è (—Ç.–∫. Qdrant —Ö—Ä–∞–Ω–∏—Ç posted_at –∫–∞–∫ keyword)
            if date_from or date_to:
                from datetime import timezone as dt_timezone
                
                filtered_results = []
                for r in enriched_results:
                    posted_at = r['posted_at']
                    
                    # –î–µ–ª–∞–µ–º –æ–±–µ –¥–∞—Ç—ã timezone-aware
                    if posted_at and posted_at.tzinfo is None:
                        posted_at = posted_at.replace(tzinfo=dt_timezone.utc)
                    
                    df = date_from.replace(tzinfo=dt_timezone.utc) if date_from and date_from.tzinfo is None else date_from
                    dt = date_to.replace(tzinfo=dt_timezone.utc) if date_to and date_to.tzinfo is None else date_to
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
                    if (not df or posted_at >= df) and (not dt or posted_at <= dt):
                        filtered_results.append(r)
                
                enriched_results = filtered_results
            
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(enriched_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è user {user_id}")
            return enriched_results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            raise
    
    async def _enrich_search_results(
        self,
        search_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        –û–±–æ–≥–∞—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î
        
        Args:
            search_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ Qdrant
            
        Returns:
            –û–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        """
        db = SessionLocal()
        try:
            enriched = []
            
            for result in search_results:
                payload = result["payload"]
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º post_id –∏–∑ payload
                post_id = payload.get("post_id")
                if not post_id:
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç –∏–∑ –ë–î –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                post = db.query(Post).filter(Post.id == post_id).first()
                if not post:
                    continue
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                enriched_result = {
                    "post_id": post.id,
                    "score": result["score"],
                    "text": payload.get("text", post.text),
                    "channel_id": post.channel_id,
                    "channel_username": post.channel.channel_username,
                    "posted_at": post.posted_at,
                    "url": post.url,
                    "tags": post.tags,
                    "views": post.views,
                    "chunk_info": {
                        "chunk_index": payload.get("chunk_index", 0),
                        "total_chunks": payload.get("total_chunks", 1),
                        "is_chunked": payload.get("total_chunks", 1) > 1
                    }
                }
                
                enriched.append(enriched_result)
            
            return enriched
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return []
        finally:
            db.close()
    
    async def search_similar_posts(
        self,
        post_id: int,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –ø–æ—Å—Ç—ã
        
        Args:
            post_id: ID –ø–æ—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–æ—Å—Ç–æ–≤
        """
        db = SessionLocal()
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç
            post = db.query(Post).filter(Post.id == post_id).first()
            if not post or not post.text:
                logger.warning(f"‚ö†Ô∏è –ü–æ—Å—Ç {post_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
                return []
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –∫–∞–∫ –∑–∞–ø—Ä–æ—Å
            return await self.search(
                query=post.text,
                user_id=post.user_id,
                limit=limit + 1  # +1 —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —Å–∞–º –ø–æ—Å—Ç
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –ø–æ—Å—Ç–æ–≤: {e}")
            return []
        finally:
            db.close()
    
    async def get_popular_tags(
        self,
        user_id: int,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–≥–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ—Å—Ç–æ–≤
        """
        db = SessionLocal()
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —Ç–µ–≥–∞–º–∏
            posts = db.query(Post).filter(
                Post.user_id == user_id,
                Post.tags != None
            ).all()
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–≥–∏
            tag_counts = {}
            for post in posts:
                if post.tags:
                    for tag in post.tags:
                        tag = tag.lower().strip()
                        if tag:
                            tag_counts[tag] = tag_counts.get(tag, 0) + 1
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
            sorted_tags = sorted(
                tag_counts.items(),
                key=lambda x: x[1],
                reverse=True
            )[:limit]
            
            return [
                {"tag": tag, "count": count}
                for tag, count in sorted_tags
            ]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–≥–æ–≤: {e}")
            return []
        finally:
            db.close()
    
    async def get_channel_stats(
        self,
        user_id: int
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–Ω–∞–ª–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º
        """
        db = SessionLocal()
        try:
            from sqlalchemy import func
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –ø–æ –∫–∞–Ω–∞–ª–∞–º
            stats = db.query(
                Post.channel_id,
                Channel.channel_username,
                Channel.channel_title,
                func.count(Post.id).label('posts_count'),
                func.max(Post.posted_at).label('last_post_at')
            ).join(
                Channel, Post.channel_id == Channel.id
            ).filter(
                Post.user_id == user_id
            ).group_by(
                Post.channel_id,
                Channel.channel_username,
                Channel.channel_title
            ).order_by(
                func.count(Post.id).desc()
            ).all()
            
            return [
                {
                    "channel_id": stat.channel_id,
                    "channel_username": stat.channel_username,
                    "channel_title": stat.channel_title,
                    "posts_count": stat.posts_count,
                    "last_post_at": stat.last_post_at
                }
                for stat in stats
            ]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–Ω–∞–ª–æ–≤: {e}")
            return []
        finally:
            db.close()


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
search_service = SearchService()

