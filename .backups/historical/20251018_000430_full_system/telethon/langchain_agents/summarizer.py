"""
Context Summarizer Agent

–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥ —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç GigaChat –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è —Å Pydantic structured output.
"""

import logging
from typing import Dict, Any, List

from .base import BaseAgent
from .config import get_llm_for_agent
from .schemas import SummarizerOutput

logger = logging.getLogger(__name__)


class ContextSummarizerAgent(BaseAgent):
    """–ê–≥–µ–Ω—Ç –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å Pydantic structured output"""
    
    def __init__(self):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GigaChat –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ (—Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥)
        llm = get_llm_for_agent("emotion_analysis")
        
        system_prompt = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–æ–≤.

–¢–í–û–Ø –†–û–õ–¨: –°–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–∑—é–º–µ, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–¥ —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –¥–∏–∞–ª–æ–≥–∞.
–ì–†–ê–ù–ò–¶–´: –†–∞–±–æ—Ç–∞–µ—à—å —Ç–æ–ª—å–∫–æ —Å —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–µ–º—ã –∏–ª–∏ —ç–º–æ—Ü–∏–∏.

–ê–î–ê–ü–¢–ê–¶–ò–Ø –ü–û–î –ö–û–ù–¢–ï–ö–°–¢:
- –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ (micro, brief, standard, detailed, comprehensive)
- –¢–∏–ø –¥–∏–∞–ª–æ–≥–∞ (discussion, question_answer, announcement, mixed)
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä—É
- –†–æ–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –∏—Ö –≤–∫–ª–∞–¥

–°–¢–†–£–ö–¢–£–†–ê –†–ï–ó–Æ–ú–ï:
- main_points: –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—É–Ω–∫—Ç—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è
- key_decisions: –∫–ª—é—á–µ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥—ã
- outstanding_issues: –Ω–µ—Ä–µ—à–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
- next_steps: —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –∏ –¥–µ–π—Å—Ç–≤–∏—è
- summary_text: –∫—Ä–∞—Ç–∫–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ

–ü–†–ò–ú–ï–†–´ –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –í–´–í–û–î–ê:
{{
  "summary": {{
    "main_points": ["–û–±—Å—É–∂–¥–µ–Ω–∏–µ Docker –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏", "–í–æ–ø—Ä–æ—Å—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ API"],
    "key_decisions": ["–ü—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Docker Compose", "–£—Ç–≤–µ—Ä–∂–¥–µ–Ω –ø–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"],
    "outstanding_issues": ["–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"],
    "next_steps": ["–ù–∞—Å—Ç—Ä–æ–∏—Ç—å CI/CD pipeline", "–ü—Ä–æ–≤–µ—Å—Ç–∏ code review"],
    "summary_text": "–ö–æ–º–∞–Ω–¥–∞ –æ–±—Å—É–¥–∏–ª–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞..."
  }},
  "context_adaptation": {{
    "detail_level": "standard",
    "dialogue_type": "discussion",
    "focus_areas": ["–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å"],
    "summary_style": "balanced"
  }}
}}

–í–ê–ñ–ù–û:
- –ê–¥–∞–ø—Ç–∏—Ä—É–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ–¥ —Ç—Ä–µ–±—É–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å
- –°–æ—Ö—Ä–∞–Ω—è–π –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Ä–µ—à–µ–Ω–∏—è
- –í—ã–¥–µ–ª—è–π –Ω–µ—Ä–µ—à–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
- –ö–†–ò–¢–ò–ß–ù–û: –°–æ—Ö—Ä–∞–Ω—è–π —Ä–µ–∞–ª—å–Ω—ã–µ usernames —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""

        super().__init__(
            llm=llm,
            system_prompt=system_prompt,
            agent_name="context_summarizer",
            output_model=SummarizerOutput,
            timeout=30.0
        )
    
    async def _process_input(self, input_data: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ user message –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ"""
        messages_text = input_data.get("messages_text", input_data.get("messages", ""))
        assessment = input_data.get("assessment", None)
        if assessment and hasattr(assessment, 'detail_level'):
            detail_level = assessment.detail_level
        else:
            detail_level = "standard"
            
        if assessment and hasattr(assessment, 'dialogue_type'):
            dialogue_type = assessment.dialogue_type
        else:
            dialogue_type = "mixed"
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        topics_obj = input_data.get("topics", None)
        emotions_obj = input_data.get("emotions", None)
        speakers_obj = input_data.get("speakers", None)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Pydantic –æ–±—ä–µ–∫—Ç–æ–≤ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä–µ–π
        topics = []
        if topics_obj:
            if hasattr(topics_obj, 'topics'):
                topics = topics_obj.topics
            elif isinstance(topics_obj, dict):
                topics = topics_obj.get("topics", [])
        
        emotions = {}
        if emotions_obj:
            if hasattr(emotions_obj, 'overall_tone'):
                emotions = {
                    'overall_tone': emotions_obj.overall_tone,
                    'atmosphere': emotions_obj.atmosphere
                }
            elif isinstance(emotions_obj, dict):
                emotions = emotions_obj
        
        speakers = []
        if speakers_obj:
            if hasattr(speakers_obj, 'speakers'):
                speakers = speakers_obj.speakers
            elif isinstance(speakers_obj, dict):
                speakers = speakers_obj.get("speakers", [])
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_parts = []
        
        if topics:
            if hasattr(topics[0], 'name'):
                topics_text = ", ".join([t.name for t in topics[:5]])
            else:
                topics_text = ", ".join([t.get("name", "") for t in topics[:5]])
            context_parts.append(f"–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã: {topics_text}")
        
        if emotions.get("overall_tone"):
            context_parts.append(f"–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω: {emotions['overall_tone']}")
        
        if speakers:
            if hasattr(speakers[0], 'username'):
                speakers_text = ", ".join([s.username for s in speakers[:3]])
            else:
                speakers_text = ", ".join([s.get("username", "") for s in speakers[:3]])
            context_parts.append(f"–ö–ª—é—á–µ–≤—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏: {speakers_text}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤
        if not context_parts:
            context_parts.append("–î–∏–∞–ª–æ–≥ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–µ–º")
        
        context = "\n".join(context_parts)
        
        user_message = f"""–°–æ–∑–¥–∞–π –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞.

–£–†–û–í–ï–ù–¨ –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–ò: {detail_level}
–¢–ò–ü –î–ò–ê–õ–û–ì–ê: {dialogue_type}

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–î–ò–ê–õ–û–ì:
{messages_text}

–°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–¥ —É–∫–∞–∑–∞–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —Ç–∏–ø –¥–∏–∞–ª–æ–≥–∞."""

        return user_message
    
    async def _process_output(self, output: SummarizerOutput, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ"""
        try:
            # Pydantic –º–æ–¥–µ–ª—å —É–∂–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∞
            result = {
                "summary": {
                    "main_points": output.summary.main_points,
                    "key_decisions": output.summary.key_decisions,
                    "outstanding_issues": output.summary.outstanding_issues,
                    "next_steps": output.summary.next_steps,
                    "summary_text": output.summary.summary_text
                },
                "context_adaptation": {
                    "detail_level": output.context_adaptation.detail_level,
                    "dialogue_type": output.context_adaptation.dialogue_type,
                    "focus_areas": output.context_adaptation.focus_areas,
                    "summary_style": output.context_adaptation.summary_style
                }
            }
            
            logger.info(f"üìù –†–µ–∑—é–º–µ —Å–æ–∑–¥–∞–Ω–æ: {len(output.summary.main_points)} –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ: {e}")
            return {
                "summary": {
                    "main_points": [],
                    "key_decisions": [],
                    "outstanding_issues": [],
                    "next_steps": [],
                    "summary_text": "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ"
                },
                "context_adaptation": {
                    "detail_level": "standard",
                    "dialogue_type": "mixed",
                    "focus_areas": [],
                    "summary_style": "concise"
                },
                "error": str(e),
                "fallback": True
            }