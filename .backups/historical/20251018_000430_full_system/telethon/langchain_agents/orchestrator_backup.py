"""
Digest Orchestrator - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∞–≥–µ–Ω—Ç–æ–≤

–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è 9-–∞–≥–µ–Ω—Ç–Ω–æ–π sequential pipeline.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LCEL –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤.

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
1. Dialogue Assessor (—ç–≤—Ä–∏—Å—Ç–∏–∫–∏) ‚Üí detail_level, dialogue_type
2. Topic Extractor (GigaChat) ‚Üí topics —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
3. Emotion Analyzer (GigaChat-Pro) ‚Üí overall_tone, atmosphere
4. Speaker Analyzer (GigaChat-Pro) ‚Üí —Ä–æ–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
5. Context Summarizer (GigaChat-Pro) ‚Üí –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–µ–∑—é–º–µ
6. Key Moments (GigaChat-Pro, conditional) ‚Üí —Ä–µ—à–µ–Ω–∏—è, –≤–æ–ø—Ä–æ—Å—ã
7. Timeline Builder (GigaChat-Pro, conditional) ‚Üí —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—è
8. Context Links (GigaChat, conditional) ‚Üí –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫
9. Supervisor Synthesizer (GigaChat-Pro) ‚Üí —Ñ–∏–Ω–∞–ª—å–Ω—ã–π HTML –¥–∞–π–¥–∂–µ—Å—Ç
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone

from langchain_core.runnables import RunnableParallel, RunnableSequence

from .assessor import DialogueAssessorAgent
from .topic_extractor import TopicExtractorAgent
from .emotion_analyzer import EmotionAnalyzerAgent
from .speaker_analyzer import SpeakerAnalyzerAgent
from .summarizer import ContextSummarizerAgent
from .key_moments import KeyMomentsAgent
from .timeline import TimelineBuilderAgent
from .context_links import ContextLinksAgent
from .supervisor import SupervisorSynthesizerAgent
from .config import config
from .schemas import AgentStatus
from .observability import log_orchestrator_metrics


logger = logging.getLogger(__name__)


class DigestOrchestrator:
    """
    –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∞–≥–µ–Ω—Ç–æ–≤ –¥–∞–π–¥–∂–µ—Å—Ç–∞
    
    –£–ø—Ä–∞–≤–ª—è–µ—Ç:
    - Sequential execution –æ—Å–Ω–æ–≤–Ω–æ–π pipeline
    - Parallel execution –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ (Topics + Emotions)
    - Conditional execution –∞–≥–µ–Ω—Ç–æ–≤ 6-8
    - Error handling –∏ fallback
    - Performance monitoring
    """
    
    def __init__(self):
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Digest Orchestrator")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
        self.assessor = DialogueAssessorAgent()
        self.topic_extractor = TopicExtractorAgent()
        self.emotion_analyzer = EmotionAnalyzerAgent()
        self.speaker_analyzer = SpeakerAnalyzerAgent()
        self.summarizer = ContextSummarizerAgent()
        self.key_moments = KeyMomentsAgent()
        self.timeline = TimelineBuilderAgent()
        self.context_links = ContextLinksAgent()
        self.supervisor = SupervisorSynthesizerAgent()
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞—Ç—É—Å–∞ –∞–≥–µ–Ω—Ç–æ–≤
        self.agents_status: List[AgentStatus] = []
        
        logger.info("‚úÖ –í—Å–µ –∞–≥–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    
    def _record_agent_status(self, agent_name: str, status: str, execution_time: float, 
                           error_message: Optional[str] = None, output_summary: Optional[str] = None):
        """–ó–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞"""
        agent_status = AgentStatus(
            agent_name=agent_name,
            status=status,
            execution_time=execution_time,
            error_message=error_message,
            output_summary=output_summary
        )
        self.agents_status.append(agent_status)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        if status == "success":
            logger.info(f"‚úÖ {agent_name}: {output_summary} ({execution_time:.2f}s)")
        elif status == "error":
            logger.error(f"‚ùå {agent_name}: {error_message} ({execution_time:.2f}s)")
        elif status == "fallback":
            logger.warning(f"üîÑ {agent_name}: fallback used - {error_message} ({execution_time:.2f}s)")
    
    async def generate_digest(
        self, 
        messages: List[Any], 
        hours: int = 24,
        user_id: Optional[int] = None,
        group_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—É—é 9-–∞–≥–µ–Ω—Ç–Ω—É—é pipeline
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π Telegram
            hours: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
            group_id: ID –≥—Ä—É–ø–ø—ã (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
            
        Returns:
            Dict —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –¥–∞–π–¥–∂–µ—Å—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        start_time = datetime.now(timezone.utc)
        
        try:
            logger.info(f"üéØ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_id}")
            logger.info(f"   –°–æ–æ–±—â–µ–Ω–∏–π: {len(messages)}")
            logger.info(f"   –ß–∞—Å–æ–≤: {hours}")
            logger.info(f"   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_id}")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            messages_text = self._format_messages_for_analysis(messages)
            input_data = {
                "messages": messages,
                "messages_text": messages_text,
                "hours": hours,
                "user_id": user_id,
                "group_id": group_id
            }
            
            # Phase 1: Dialogue Assessor (–±—ã—Å—Ç—Ä—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏)
            logger.info("üìä Phase 1: Dialogue Assessor")
            assessment = await self.assessor.ainvoke(input_data)
            input_data["assessment"] = assessment
            
            logger.info(f"   –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {assessment.get('detail_level')}")
            logger.info(f"   –¢–∏–ø –¥–∏–∞–ª–æ–≥–∞: {assessment.get('dialogue_type')}")
            
            # Phase 2-3: Topics + Emotions (PARALLEL execution)
            logger.info("üîÑ Phase 2-3: Topics + Emotions (Parallel)")
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Topics –∏ Emotions
            topics_task = asyncio.create_task(self.topic_extractor.ainvoke(input_data))
            emotions_task = asyncio.create_task(self.emotion_analyzer.ainvoke(input_data))
            
            topics_result, emotions_result = await asyncio.gather(topics_task, emotions_task)
            
            step1_results = {
                "topics": topics_result,
                "emotions": emotions_result
            }
            input_data.update(step1_results)
            
            logger.info(f"   –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–µ–º: {len(step1_results.get('topics', {}).get('topics', []))}")
            logger.info(f"   –¢–æ–Ω: {step1_results.get('emotions', {}).get('overall_tone')}")
            
            # Phase 4: Speaker Analyzer (sequential, –Ω—É–∂–Ω—ã topics + emotions)
            logger.info("üë• Phase 4: Speaker Analyzer")
            speakers = await self.speaker_analyzer.ainvoke(input_data)
            input_data["speakers"] = speakers
            
            logger.info(f"   –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(speakers.get('speakers', []))}")
            
            # Phase 5: Context Summarizer (sequential, –Ω—É–∂–Ω—ã –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ)
            logger.info("üìù Phase 5: Context Summarizer")
            summary = await self.summarizer.ainvoke(input_data)
            input_data["summary"] = summary
            
            logger.info(f"   –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: {len(summary.get('summary', {}).get('main_points', []))}")
            
            # Phase 6-8: Conditional agents
            conditional_results = await self._execute_conditional_agents(input_data, assessment)
            input_data.update(conditional_results)
            
            # Phase 9: Supervisor Synthesizer (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑)
            logger.info("üé≠ Phase 9: Supervisor Synthesizer")
            final_digest = await self.supervisor.ainvoke(input_data)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = self._prepare_final_result(final_digest, input_data, start_time)
            
            end_time = datetime.now(timezone.utc)
            duration = (end_time - start_time).total_seconds()
            logger.info(f"‚úÖ –î–∞–π–¥–∂–µ—Å—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∑–∞ {duration:.2f}s")
            logger.info(f"   –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(result.get('html_digest', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –≤ Langfuse
            log_orchestrator_metrics(
                start_time=start_time,
                end_time=end_time,
                success=True,
                user_id=user_id,
                group_id=group_id,
                result=result
            )
            
            return result
            
        except Exception as e:
            end_time = datetime.now(timezone.utc)
            duration = (end_time - start_time).total_seconds()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ {duration:.2f}s: {e}")
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –≤ Langfuse
            log_orchestrator_metrics(
                start_time=start_time,
                end_time=end_time,
                success=False,
                user_id=user_id,
                group_id=group_id,
                error=e
            )
            
            # –í–æ–∑–≤—Ä–∞—Ç fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            return await self._handle_generation_error(e, input_data, start_time)
    
    async def _execute_conditional_agents(self, input_data: Dict[str, Any], assessment: Dict[str, Any]) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —É—Å–ª–æ–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ 6-8
        
        Args:
            input_data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
            assessment: –†–µ–∑—É–ª—å—Ç–∞—Ç Dialogue Assessor
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —É—Å–ª–æ–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        """
        detail_level = assessment.get("detail_level", "standard")
        has_links = assessment.get("has_links", False)
        
        results = {}
        
        # Phase 6: Key Moments (–∞–∫—Ç–∏–≤–µ–Ω –ø—Ä–∏ detail_level >= standard)
        if detail_level in ["standard", "detailed", "comprehensive"]:
            logger.info("üîë Phase 6: Key Moments")
            try:
                key_moments = await self.key_moments.ainvoke(input_data)
                results["key_moments"] = key_moments
                
                decisions_count = len(key_moments.get("key_decisions", []))
                questions_count = len(key_moments.get("critical_questions", []))
                logger.info(f"   –†–µ—à–µ–Ω–∏–π: {decisions_count}, –í–æ–ø—Ä–æ—Å–æ–≤: {questions_count}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Key Moments: {e}")
                results["key_moments"] = {"error": str(e)}
        else:
            logger.info("‚è≠Ô∏è Phase 6: Key Moments (–ø—Ä–æ–ø—É—â–µ–Ω - —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π)")
            results["key_moments"] = {"skipped": True}
        
        # Phase 7: Timeline Builder (–∞–∫—Ç–∏–≤–µ–Ω –ø—Ä–∏ detail_level >= detailed)
        if detail_level in ["detailed", "comprehensive"]:
            logger.info("‚è∞ Phase 7: Timeline Builder")
            try:
                timeline = await self.timeline.ainvoke(input_data)
                results["timeline"] = timeline
                
                events_count = len(timeline.get("timeline_events", []))
                phases_count = len(timeline.get("discussion_phases", []))
                logger.info(f"   –°–æ–±—ã—Ç–∏–π: {events_count}, –§–∞–∑: {phases_count}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Timeline Builder: {e}")
                results["timeline"] = {"error": str(e)}
        else:
            logger.info("‚è≠Ô∏è Phase 7: Timeline Builder (–ø—Ä–æ–ø—É—â–µ–Ω - —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π)")
            results["timeline"] = {"skipped": True}
        
        # Phase 8: Context Links (–∞–∫—Ç–∏–≤–µ–Ω –ø—Ä–∏ comprehensive OR has_links)
        if detail_level == "comprehensive" or has_links:
            logger.info("üîó Phase 8: Context Links")
            try:
                context_links = await self.context_links.ainvoke(input_data)
                results["context_links"] = context_links
                
                external_links = len(context_links.get("external_links", []))
                telegram_links = len(context_links.get("telegram_links", []))
                logger.info(f"   –í–Ω–µ—à–Ω–∏—Ö —Å—Å—ã–ª–æ–∫: {external_links}, Telegram —Å—Å—ã–ª–æ–∫: {telegram_links}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Context Links: {e}")
                results["context_links"] = {"error": str(e)}
        else:
            logger.info("‚è≠Ô∏è Phase 8: Context Links (–ø—Ä–æ–ø—É—â–µ–Ω - –Ω–µ—Ç —Å—Å—ã–ª–æ–∫ –∏ —É—Ä–æ–≤–µ–Ω—å –Ω–µ comprehensive)")
            results["context_links"] = {"skipped": True}
        
        return results
    
    def _format_messages_for_analysis(self, messages: List[Any]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–≥–µ–Ω—Ç–∞–º–∏
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π Telegram
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        """
        formatted_lines = []
        
        for i, msg in enumerate(messages, 1):
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è - –ò–°–ü–†–ê–í–õ–ï–ù–û
            if hasattr(msg, 'text') and msg.text:
                text = msg.text.strip()
            else:
                text = "[—Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞]"
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ username - –ò–°–ü–†–ê–í–õ–ï–ù–û
            username = "unknown"
            if hasattr(msg, 'sender') and msg.sender:
                if hasattr(msg.sender, 'username') and msg.sender.username:
                    username = msg.sender.username
                elif hasattr(msg.sender, 'first_name') and msg.sender.first_name:
                    username = msg.sender.first_name
                elif hasattr(msg.sender, 'id'):
                    username = f"user_{msg.sender.id}"
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            timestamp = ""
            if hasattr(msg, 'date') and msg.date:
                timestamp = msg.date.strftime("%H:%M")
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
            if timestamp:
                line = f"[{i}] {username} ({timestamp}): {text}"
            else:
                line = f"[{i}] {username}: {text}"
            
            formatted_lines.append(line)
        
        logger.debug(f"–û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(formatted_lines)} —Å–æ–æ–±—â–µ–Ω–∏–π")
        return "\n".join(formatted_lines)
    
    def _format_messages_to_langchain(self, messages: List[Any]) -> List[Any]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Telethon messages –≤ LangChain Messages
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ Telethon Message objects
            
        Returns:
            –°–ø–∏—Å–æ–∫ LangChain BaseMessage objects
        """
        from langchain_core.messages import HumanMessage
        
        langchain_messages = []
        
        for msg in messages:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ username
            username = "Unknown"
            if hasattr(msg, 'sender') and msg.sender:
                if hasattr(msg.sender, 'username') and msg.sender.username:
                    username = msg.sender.username
                elif hasattr(msg.sender, 'first_name') and msg.sender.first_name:
                    username = msg.sender.first_name
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text = msg.text if hasattr(msg, 'text') and msg.text else "[no text]"
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ timestamp
            timestamp = msg.date.isoformat() if hasattr(msg, 'date') else None
            
            # –°–æ–∑–¥–∞–Ω–∏–µ LangChain message
            langchain_msg = HumanMessage(
                content=text,
                additional_kwargs={
                    "username": username,
                    "timestamp": timestamp,
                    "message_id": msg.id if hasattr(msg, 'id') else None
                }
            )
            langchain_messages.append(langchain_msg)
        
        logger.info(f"Converted {len(langchain_messages)} messages to LangChain format")
        logger.debug(f"Usernames: {set(m.additional_kwargs['username'] for m in langchain_messages)}")
        
        return langchain_messages
    
    def _prepare_final_result(
        self, 
        final_digest: Dict[str, Any], 
        input_data: Dict[str, Any], 
        start_time: datetime
    ) -> Dict[str, Any]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        
        Args:
            final_digest: –†–µ–∑—É–ª—å—Ç–∞—Ç Supervisor Synthesizer
            input_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        assessment = input_data.get("assessment", {})
        
        return {
            # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            "html_digest": final_digest.get("html_digest", ""),
            "metadata": final_digest.get("metadata", {}),
            "sections": final_digest.get("sections", {}),
            
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            "generation_metadata": {
                "duration_seconds": duration,
                "start_time": start_time.isoformat(),
                "end_time": datetime.now(timezone.utc).isoformat(),
                "user_id": input_data.get("user_id"),
                "group_id": input_data.get("group_id"),
                "message_count": len(input_data.get("messages", [])),
                "hours_analyzed": input_data.get("hours", 24)
            },
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
            "agent_results": {
                "assessment": input_data.get("assessment", {}),
                "topics": input_data.get("topics", {}),
                "emotions": input_data.get("emotions", {}),
                "speakers": input_data.get("speakers", {}),
                "summary": input_data.get("summary", {}),
                "key_moments": input_data.get("key_moments", {}),
                "timeline": input_data.get("timeline", {}),
                "context_links": input_data.get("context_links", {})
            },
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤
            "agent_statistics": {
                "agents_executed": self._count_executed_agents(input_data),
                "detail_level": assessment.get("detail_level", "standard"),
                "dialogue_type": assessment.get("dialogue_type", "mixed"),
                "participants": assessment.get("participants", 0),
                "has_links": assessment.get("has_links", False)
            }
        }
    
    def _count_executed_agents(self, input_data: Dict[str, Any]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
        count = 5  # –ë–∞–∑–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã –≤—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        if input_data.get("key_moments", {}).get("skipped") is not True:
            count += 1
        
        if input_data.get("timeline", {}).get("skipped") is not True:
            count += 1
        
        if input_data.get("context_links", {}).get("skipped") is not True:
            count += 1
        
        count += 1  # Supervisor –≤—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
        
        return count
    
    async def _handle_generation_error(
        self, 
        error: Exception, 
        input_data: Dict[str, Any], 
        start_time: datetime
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        
        Args:
            error: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ
            input_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
            
        Returns:
            Fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        """
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        assessment = input_data.get("assessment", {})
        
        # –ü—Ä–æ—Å—Ç–æ–π fallback –¥–∞–π–¥–∂–µ—Å—Ç
        fallback_html = f"""<b>–î–∞–π–¥–∂–µ—Å—Ç –¥–∏–∞–ª–æ–≥–∞</b>

<i>–°—Ç–∞—Ç—É—Å:</i> <i>–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏</i>

<b>–û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:</b>
- –°–æ–æ–±—â–µ–Ω–∏–π: {len(input_data.get('messages', []))}
- –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {assessment.get('detail_level', 'standard')}
- –¢–∏–ø –¥–∏–∞–ª–æ–≥–∞: {assessment.get('dialogue_type', 'mixed')}

<b>–û—à–∏–±–∫–∞:</b>
<code>{str(error)}</code>

<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–∑–∂–µ</i>"""
        
        return {
            "html_digest": fallback_html,
            "metadata": {
                "detail_level": assessment.get("detail_level", "standard"),
                "dialogue_type": assessment.get("dialogue_type", "mixed"),
                "participants_count": assessment.get("participants", 0),
                "message_count": len(input_data.get("messages", [])),
                "generation_timestamp": datetime.now(timezone.utc).isoformat()
            },
            "sections": {
                "summary": "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞",
                "topics": "",
                "decisions": "",
                "participants": "",
                "resources": ""
            },
            "generation_metadata": {
                "duration_seconds": duration,
                "start_time": start_time.isoformat(),
                "end_time": datetime.now(timezone.utc).isoformat(),
                "user_id": input_data.get("user_id"),
                "group_id": input_data.get("group_id"),
                "message_count": len(input_data.get("messages", [])),
                "hours_analyzed": input_data.get("hours", 24),
                "error": str(error)
            },
            "agent_results": {},
            "agent_statistics": {
                "agents_executed": 0,
                "detail_level": assessment.get("detail_level", "standard"),
                "dialogue_type": assessment.get("dialogue_type", "mixed"),
                "participants": assessment.get("participants", 0),
                "has_links": assessment.get("has_links", False),
                "error": True
            }
        }
