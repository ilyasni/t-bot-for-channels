{
  "name": "Agent: Topic Extractor",
  "nodes": [
    {
      "parameters": {},
      "id": "execute-workflow-trigger",
      "name": "Execute Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [250, 300]
    },
    {
      "parameters": {
        "jsCode": "// Prepare HTTP Request data for topic extraction\nconst items = $input.all();\nconst data = items[0].json;\n\nconst messagesText = data.messages_text || \"\";\nconst hours = data.hours || 24;\nconst assessment = data.assessment || {};\nconst detailLevel = assessment.detail_level || \"standard\";\nconst dialogueType = assessment.dialogue_type || \"casual_chat\";\nconst messageCount = assessment.message_count || 0;\n\n// Calculate max_tokens safely (no optional chaining in n8n)\nconst maxTokens = (assessment.token_budgets && assessment.token_budgets.topics) ? assessment.token_budgets.topics : 500;\n\n// Adaptive topic count\nconst topicCounts = {\n  micro: 1,\n  minimal: \"2-3\",\n  standard: \"3-5\",\n  detailed: \"5-8\",\n  comprehensive: \"8-12\"\n};\nconst targetTopicCount = topicCounts[detailLevel] || \"3-5\";\n\n// Build system message\nconst systemMessage = \"–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —Ç–µ–º –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –Ω–∞—Ö–æ–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏. –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON: {\\\"topics\\\": [{\\\"name\\\": \\\"...\\\", \\\"priority\\\": \\\"high|medium|low\\\", \\\"subtopics\\\": [...]}]}\";\n\n// Build user message\nconst userMessage = `–ò–∑–≤–ª–µ–∫–∏ —Ç–µ–º—ã –∏–∑ –¥–∏–∞–ª–æ–≥–∞ –≤ Telegram –≥—Ä—É–ø–ø–µ.\\n\\nASSESSMENT –ö–û–ù–¢–ï–ö–°–¢:\\n- –¢–∏–ø –¥–∏–∞–ª–æ–≥–∞: ${dialogueType}\\n- –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: ${detailLevel}\\n- –°–æ–æ–±—â–µ–Ω–∏–π: ${messageCount}\\n- –ü–µ—Ä–∏–æ–¥: ${hours} —á–∞—Å–æ–≤\\n\\n–°–û–û–ë–©–ï–ù–ò–Ø:\\n${messagesText}\\n\\n=== –ó–ê–î–ê–ß–ê ===\\n\\n–ò–∑–≤–ª–µ–∫–∏ ${targetTopicCount} –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º –æ–±—Å—É–∂–¥–µ–Ω–∏—è.\\n\\n${detailLevel === 'micro' ? '–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Å–∞–º—É—é –≥–ª–∞–≤–Ω—É—é —Ç–µ–º—É.' : ''}\\n\\n–î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —É–∫–∞–∂–∏:\\n- name: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã (–∫—Ä–∞—Ç–∫–æ–µ)\\n- priority: high | medium | low (–≤–∞–∂–Ω–æ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–∏–∞–ª–æ–≥–∞)\\n${detailLevel !== 'micro' && detailLevel !== 'minimal' ? '- message_count: –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π\\n- subtopics: —Å–ø–∏—Å–æ–∫ –ø–æ–¥—Ç–µ–º (–µ—Å–ª–∏ –µ—Å—Ç—å)' : ''}\\n\\n–§–û–†–ú–ê–¢:\\n{\\n  \"topics\": [\\n    {\\n      \"name\": \"–ü—Ä–æ–±–ª–µ–º–∞ —Å –≤–µ–±–≤—å—é\",\\n      \"priority\": \"high\"${detailLevel !== 'micro' && detailLevel !== 'minimal' ? ',\\n      \"message_count\": 15,\\n      \"subtopics\": [\"–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\", \"–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\"]' : ''}\\n    }\\n  ]\\n}\\n\\n–í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ markdown –±–ª–æ–∫–æ–≤!`;\n\nreturn [\n  {\n    json: {\n      system_message: systemMessage,\n      user_message: userMessage,\n      max_tokens: maxTokens,\n      hours: hours,\n      detail_level: detailLevel\n    }\n  }\n];"
      },
      "id": "prepare-prompt",
      "name": "Prepare Topic Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [450, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://gpt2giga-proxy:8090/v1/chat/completions",
        "authentication": "none",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\"model\": \"GigaChat\", \"messages\": [{\"role\": \"system\", \"content\": $json.system_message}, {\"role\": \"user\", \"content\": $json.user_message}], \"temperature\": 0.1, \"max_tokens\": $json.max_tokens, \"response_format\": {\"type\": \"json_object\"}} }}",
        "options": {
          "timeout": 60000
        }
      },
      "id": "gigachat-call",
      "name": "GigaChat: Extract Topics",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [650, 300]
    },
    {
      "parameters": {
        "jsCode": "// Parse GigaChat response from gpt2giga proxy\nconst response = $input.first().json.choices?.[0]?.message?.content || '{}';\n\nconsole.log('üì• GigaChat response received:', response.substring(0, 100));\n\nreturn [\n  {\n    json: {\n      raw_content: response\n    }\n  }\n];"
      },
      "id": "parse-response",
      "name": "Parse Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [850, 300]
    },
    {
      "parameters": {
        "workflowId": "utility_json_guardrail",
        "source": "database",
        "inputData": {
          "values": [
            {
              "json": {
                "raw_content": "={{ $json.raw_content }}",
                "data_type": "topics",
                "original_messages": "={{ $execution.customData.getAll().original_messages }}"
              }
            }
          ]
        }
      },
      "id": "execute-guardrail",
      "name": "Execute Guardrail",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1,
      "position": [1050, 300]
    }
  ],
  "connections": {
    "Execute Workflow Trigger": {
      "main": [
        [
          {
            "node": "Prepare Topic Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Topic Prompt": {
      "main": [
        [
          {
            "node": "GigaChat: Extract Topics",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GigaChat: Extract Topics": {
      "main": [
        [
          {
            "node": "Parse Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Response": {
      "main": [
        [
          {
            "node": "Execute Guardrail",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2025-10-13T16:10:00.000Z",
  "versionId": "1"
}

