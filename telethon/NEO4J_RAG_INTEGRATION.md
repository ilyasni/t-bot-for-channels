# Neo4j + RAG Hybrid Integration - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–î–∞—Ç–∞:** 14 –æ–∫—Ç—è–±—Ä—è 2025  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ  
**–ü–æ–¥—Ö–æ–¥:** Hybrid (Qdrant + Neo4j)

---

## üéØ –ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

### 1. Neo4j Client Extensions

**–§–∞–π–ª:** `telethon/graph/neo4j_client.py`

**–ù–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è RAG:**

```python
# –ì—Ä–∞—Ñ-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ—Å—Ç–∞
context = await neo4j_client.get_post_context(post_id=123)
# Returns: {
#     "related_posts": [...],    # –ß–µ—Ä–µ–∑ –æ–±—â–∏–µ —Ç–µ–≥–∏
#     "tag_cluster": [...],       # –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏
#     "channel_posts": [...]      # –î—Ä—É–≥–∏–µ –ø–æ—Å—Ç—ã –∫–∞–Ω–∞–ª–∞
# }

# Trending tags –∑–∞ –ø–µ—Ä–∏–æ–¥
trending = await neo4j_client.get_trending_tags(days=7, limit=10)
# Returns: [{"name": "AI", "posts_count": 125, "trend_score": 15.5}, ...]

# Batch —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
expanded = await neo4j_client.expand_with_graph(
    post_ids=[123, 456, 789],
    limit_per_post=3
)
# Returns: [{"source_post_id": 123, "related_posts": [...]}, ...]
```

---

### 2. Enhanced Search Service

**–§–∞–π–ª:** `telethon/rag_service/enhanced_search.py`

**Hybrid search: Qdrant + Neo4j**

```python
from rag_service.enhanced_search import enhanced_search_service

# Hybrid search —Å graph context
results = await enhanced_search_service.search_with_graph_context(
    query="AI –Ω–æ–≤–æ—Å—Ç–∏",
    user_id=123,
    limit=10,
    graph_weight=0.3  # 70% vector + 30% graph
)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å combined score:
# [{
#     "post_id": 123,
#     "text": "...",
#     "vector_score": 0.85,
#     "graph_score": 0.65,
#     "combined_score": 0.79  # (0.7*0.85 + 0.3*0.65)
# }]
```

**Graph-aware ranking:**
- Tag overlap —Å user interests (+0.2)
- –ü—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –≤ graph context (+0.3)
- Trending tags bonus (+0.2)
- Recency boost (+0.2)

---

### 3. AI Digest Graph Topics

**–§–∞–π–ª:** `telethon/rag_service/ai_digest_generator.py`

**–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ `_get_user_interests()`:**

```python
# –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 4 –∏—Å—Ç–æ—á–Ω–∏–∫–∞:
# 1. –í—Ä—É—á–Ω—É—é —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã (highest priority)
# 2. –¢–µ–º—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ RAG –∑–∞–ø—Ä–æ—Å–æ–≤
# 3. NEW: –¢–æ–ø —Ç–µ–≥–∏ –∏–∑ Neo4j –≥—Ä–∞—Ñ–∞ (—Ä–µ–∞–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
# 4. NEW: Trending tags (—á—Ç–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ —Å–µ–π—á–∞—Å)

topics = await ai_digest_generator._get_user_interests(
    user_id=123,
    preferred_topics=["–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã"]
)
# Returns: ["–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã", "bitcoin", "AI", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", ...]
#           ‚Üë manual      ‚Üë graph     ‚Üë trending  ‚Üë history
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
- –£—á–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è (–Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤)
- –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Ç—Ä–µ–Ω–¥–∞–º

---

### 4. Redis Cache Layer

**–§–∞–π–ª:** `telethon/rag_service/graph_cache.py`

**–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ graph queries:**

```python
from rag_service.graph_cache import graph_cache

# Cached calls (—Å TTL)
interests = await graph_cache.get_user_interests(user_id=123)  # TTL: 1h
trending = await graph_cache.get_trending_tags(days=7)          # TTL: 6h
context = await graph_cache.get_post_context(post_id=123)       # TTL: 24h

# Cache invalidation
await graph_cache.invalidate_user_interests(user_id=123)
await graph_cache.invalidate_trending()
```

**Cache keys:**
- `graph:interests:{user_id}` (1 hour)
- `graph:trending:tags:d{days}` (6 hours)
- `graph:post_context:{post_id}` (24 hours)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Latency —Å–Ω–∏–∂–µ–Ω–∞ –Ω–∞ 50-80% –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

---

### 5. Data Retention Service

**–§–∞–π–ª—ã:**
- `telethon/maintenance/data_retention.py`
- `telethon/maintenance/cleanup_scheduler.py`

**–ê–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**

```python
from maintenance.data_retention import retention_service

# Dry run (–±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è)
result = await retention_service.cleanup_all(dry_run=True)
# {
#   "deleted_count": {"postgres": 1500, "neo4j": 1500, "qdrant": 1500},
#   "errors": []
# }

# –†–µ–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ
result = await retention_service.cleanup_all(dry_run=False)
```

**Retention period:** 120 –¥–Ω–µ–π (4 –º–µ—Å—è—Ü–∞) –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

**Cleanup strategy:**
- PostgreSQL: batch DELETE + VACUUM
- Neo4j: DETACH DELETE (batch —Å apoc.periodic.iterate)
- Qdrant: delete by filter (posted_at < cutoff_date)

**–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è:**

```python
from maintenance.cleanup_scheduler import cleanup_scheduler

# –í startup event
cleanup_scheduler.start()  # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 3:00 AM

# –í shutdown event
cleanup_scheduler.stop()
```

---

## üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
User Query
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ EnhancedSearchService        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
    ‚îú‚îÄ‚Üí [Async] Qdrant Search ‚Üí Top 20 posts (semantic)
    ‚îÇ       ‚Üì
    ‚îÇ   [Cache check]
    ‚îÇ
    ‚îî‚îÄ‚Üí [Async] Neo4j Context ‚Üí User interests + Trending
            ‚Üì
        graph_cache (Redis)
    
    ‚Üì Merge & Graph-Aware Ranking
    
Combined Score = 0.7*vector + 0.3*graph
  - Vector similarity (Qdrant)
  - Tag overlap with interests
  - Trending bonus
  - Recency boost
    
    ‚Üì
Top 10-15 posts ‚Üí LLM ‚Üí Answer
```

---

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

**–í `.env` –¥–æ–±–∞–≤–∏—Ç—å:**

```bash
# Neo4j (—É–∂–µ –µ—Å—Ç—å)
NEO4J_ENABLED=true
NEO4J_URI=bolt://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=YourSecurePassword123
NEO4J_AUTO_INDEX=true

# Data Retention
DATA_RETENTION_DAYS=120        # 4 –º–µ—Å—è—Ü–∞
CLEANUP_ENABLED=true
CLEANUP_SCHEDULE="0 3 * * *"   # Cron: 3:00 AM daily

# Graph Weight (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
GRAPH_WEIGHT=0.3  # 30% –≤–µ—Å –≥—Ä–∞—Ñ–∞ –≤ ranking (default: 0.3)
```

---

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### Use Case 1: Hybrid Search

```python
# –í RAG generator.py
from rag_service.enhanced_search import enhanced_search_service

# –í–º–µ—Å—Ç–æ search_service.search():
results = await enhanced_search_service.search_with_graph_context(
    query=user_query,
    user_id=user_id,
    limit=10
)

# Graceful degradation: –µ—Å–ª–∏ Neo4j –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí fallback –Ω–∞ Qdrant only
```

### Use Case 2: Personalized Digests

```python
# –í ai_digest_generator.py (—É–∂–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ)

# –ú–µ—Ç–æ–¥ _get_user_interests() —Ç–µ–ø–µ—Ä—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:
# 1. Manual topics
# 2. RAG history
# 3. Neo4j graph interests
# 4. Trending tags

# –†–µ–∑—É–ª—å—Ç–∞—Ç: –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ç–µ–º—ã –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤
```

### Use Case 3: Manual Cleanup

```bash
# API endpoint (–¥–æ–±–∞–≤–∏—Ç—å –≤ main.py):
POST /admin/cleanup?dry_run=true
Header: api-key: ADMIN_API_KEY

# Curl example:
curl -X POST http://localhost:8010/admin/cleanup?dry_run=true \
  -H "api-key: your_admin_key"
```

---

## üìà –ú–µ—Ç—Ä–∏–∫–∏

**Prometheus metrics (TODO):**

```python
# –í enhanced_search.py –¥–æ–±–∞–≤–∏—Ç—å:
from prometheus_client import Histogram, Counter

hybrid_search_duration = Histogram(
    'hybrid_search_duration_seconds',
    'Hybrid search latency'
)

graph_cache_hit_rate = Counter(
    'graph_cache_hits_total',
    'Graph cache hit rate',
    ['cache_type']
)
```

**–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:**
- Latency P50/P95 (target: <200ms)
- Cache hit rate (target: >70%)
- Graph availability (0/1)
- Cleanup success rate

---

## üß™ Testing

### 1. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Neo4j Extensions

```python
# Test get_post_context
context = await neo4j_client.get_post_context(post_id=123)
assert "related_posts" in context
assert "tag_cluster" in context

# Test get_trending_tags
trending = await neo4j_client.get_trending_tags(days=7, limit=10)
assert len(trending) <= 10
assert all("name" in t for t in trending)

# Test expand_with_graph
expanded = await neo4j_client.expand_with_graph(
    post_ids=[123, 456],
    limit_per_post=3
)
assert len(expanded) <= 2
```

### 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Hybrid Search

```bash
# Compare baseline vs hybrid
python -m pytest tests/test_enhanced_search.py -v

# Expected:
# - Precision@10 —É–ª—É—á—à–µ–Ω–∞ –Ω–∞ 10%+
# - Latency < 200ms P95
# - Graceful degradation —Ä–∞–±–æ—Ç–∞–µ—Ç
```

### 3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Data Retention

```bash
# Dry run
curl -X POST http://localhost:8010/admin/cleanup?dry_run=true \
  -H "api-key: test_key"

# Verify:
# - –ü–æ–¥—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
# - –ù–µ—Ç –æ—à–∏–±–æ–∫
# - –î–∞–Ω–Ω—ã–µ –Ω–µ —É–¥–∞–ª–µ–Ω—ã
```

---

## üêõ Troubleshooting

### Neo4j –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å health
curl http://localhost:8010/graph/health

# –õ–æ–≥–∏
docker logs telethon | grep -i neo4j

# –†–µ—à–µ–Ω–∏–µ: graceful degradation —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
```

### Cache –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Redis
docker logs redis

# Verify
docker exec -it redis redis-cli
> KEYS graph:*

# –†–µ—à–µ–Ω–∏–µ: cache –æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –Ω–µ–≥–æ
```

### Cleanup —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π

```bash
# Reduce batch size
# –í data_retention.py –∏–∑–º–µ–Ω–∏—Ç—å:
# batchSize: 5000 ‚Üí 1000

# OR –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL (—Å–º. plan)
```

---

## üìö Next Steps

1. **A/B Testing:**
   - 10% users ‚Üí hybrid search
   - 90% users ‚Üí current RAG
   - Measure: Precision@10, user satisfaction

2. **Query Expansion (Phase 2):**
   - –°–æ–∑–¥–∞—Ç—å `query_expander.py`
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å tag relationships –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤

3. **Metrics Dashboard:**
   - Grafana dashboard
   - Alerts –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏

4. **PostgreSQL –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ:**
   - –ú–∏–≥—Ä–∞—Ü–∏—è posts ‚Üí posts_partitioned
   - Instant cleanup —á–µ—Ä–µ–∑ DROP TABLE

---

**–°—Ç–∞—Ç—É—Å:** ‚úÖ Ready for testing

–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏!

