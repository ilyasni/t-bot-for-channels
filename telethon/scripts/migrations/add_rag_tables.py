#!/usr/bin/env python3
"""
–ú–∏–≥—Ä–∞—Ü–∏—è –ë–î: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è RAG-—Å–∏—Å—Ç–µ–º—ã

–î–æ–±–∞–≤–ª—è–µ—Ç:
- digest_settings - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- indexing_status - —Å—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤ –≤ Qdrant

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/migrations/add_rag_tables.py

–ê–≤—Ç–æ—Ä: RAG System
–î–∞—Ç–∞: 2025-01-11
"""

import os
import sys
from datetime import datetime, timezone
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from sqlalchemy import create_engine, text, inspect
from database import SessionLocal, engine
from models import Base, User, Channel, Post

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def check_table_exists(engine, table_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã"""
    inspector = inspect(engine)
    return table_name in inspector.get_table_names()


def create_digest_settings_table(engine):
    """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É digest_settings"""
    
    # SQL –¥–ª—è SQLite
    sqlite_sql = """
    CREATE TABLE IF NOT EXISTS digest_settings (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER UNIQUE NOT NULL,
        enabled BOOLEAN DEFAULT 0,
        frequency VARCHAR DEFAULT 'daily',
        time VARCHAR DEFAULT '09:00',
        days_of_week TEXT,
        timezone VARCHAR DEFAULT 'Europe/Moscow',
        channels TEXT,
        tags TEXT,
        format VARCHAR DEFAULT 'markdown',
        max_posts INTEGER DEFAULT 20,
        delivery_method VARCHAR DEFAULT 'telegram',
        email VARCHAR,
        last_sent_at TIMESTAMP,
        next_scheduled_at TIMESTAMP,
        FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
    );
    """
    
    # SQL –¥–ª—è PostgreSQL
    postgres_sql = """
    CREATE TABLE IF NOT EXISTS digest_settings (
        id SERIAL PRIMARY KEY,
        user_id INTEGER UNIQUE NOT NULL,
        enabled BOOLEAN DEFAULT FALSE,
        frequency VARCHAR DEFAULT 'daily',
        time VARCHAR DEFAULT '09:00',
        days_of_week JSON,
        timezone VARCHAR DEFAULT 'Europe/Moscow',
        channels JSON,
        tags JSON,
        format VARCHAR DEFAULT 'markdown',
        max_posts INTEGER DEFAULT 20,
        delivery_method VARCHAR DEFAULT 'telegram',
        email VARCHAR,
        last_sent_at TIMESTAMP WITH TIME ZONE,
        next_scheduled_at TIMESTAMP WITH TIME ZONE,
        FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
    );
    """
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ë–î
    db_url = str(engine.url)
    is_postgres = db_url.startswith('postgresql')
    
    sql = postgres_sql if is_postgres else sqlite_sql
    
    try:
        with engine.connect() as conn:
            conn.execute(text(sql))
            conn.commit()
        logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ digest_settings —Å–æ–∑–¥–∞–Ω–∞")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã digest_settings: {e}")
        raise


def create_indexing_status_table(engine):
    """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É indexing_status"""
    
    # SQL –¥–ª—è SQLite
    sqlite_sql = """
    CREATE TABLE IF NOT EXISTS indexing_status (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER NOT NULL,
        post_id INTEGER NOT NULL,
        indexed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        vector_id VARCHAR,
        status VARCHAR DEFAULT 'success',
        error TEXT,
        FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,
        FOREIGN KEY(post_id) REFERENCES posts(id) ON DELETE CASCADE,
        UNIQUE(user_id, post_id)
    );
    """
    
    # SQL –¥–ª—è PostgreSQL
    postgres_sql = """
    CREATE TABLE IF NOT EXISTS indexing_status (
        id SERIAL PRIMARY KEY,
        user_id INTEGER NOT NULL,
        post_id INTEGER NOT NULL,
        indexed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
        vector_id VARCHAR,
        status VARCHAR DEFAULT 'success',
        error TEXT,
        FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,
        FOREIGN KEY(post_id) REFERENCES posts(id) ON DELETE CASCADE,
        UNIQUE(user_id, post_id)
    );
    """
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ë–î
    db_url = str(engine.url)
    is_postgres = db_url.startswith('postgresql')
    
    sql = postgres_sql if is_postgres else sqlite_sql
    
    try:
        with engine.connect() as conn:
            conn.execute(text(sql))
            conn.commit()
        logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ indexing_status —Å–æ–∑–¥–∞–Ω–∞")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã indexing_status: {e}")
        raise


def create_indexes(engine):
    """–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –Ω–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü"""
    
    indexes_sql = [
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è digest_settings
        "CREATE INDEX IF NOT EXISTS idx_digest_settings_user_id ON digest_settings(user_id);",
        "CREATE INDEX IF NOT EXISTS idx_digest_settings_enabled ON digest_settings(enabled);",
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è indexing_status
        "CREATE INDEX IF NOT EXISTS idx_indexing_status_user_id ON indexing_status(user_id);",
        "CREATE INDEX IF NOT EXISTS idx_indexing_status_post_id ON indexing_status(post_id);",
        "CREATE INDEX IF NOT EXISTS idx_indexing_status_status ON indexing_status(status);",
    ]
    
    try:
        with engine.connect() as conn:
            for sql in indexes_sql:
                conn.execute(text(sql))
            conn.commit()
        logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: {e}")
        raise


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏"""
    logger.info("üîÑ –ù–∞—á–∞–ª–æ –º–∏–≥—Ä–∞—Ü–∏–∏: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è RAG-—Å–∏—Å—Ç–µ–º—ã")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
    if check_table_exists(engine, 'digest_settings'):
        logger.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ digest_settings —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    else:
        create_digest_settings_table(engine)
    
    if check_table_exists(engine, 'indexing_status'):
        logger.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ indexing_status —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    else:
        create_indexing_status_table(engine)
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
    create_indexes(engine)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    logger.info("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü:")
    inspector = inspect(engine)
    tables = inspector.get_table_names()
    
    for table in ['digest_settings', 'indexing_status']:
        if table in tables:
            columns = inspector.get_columns(table)
            logger.info(f"  ‚úÖ {table}: {len(columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        else:
            logger.error(f"  ‚ùå {table}: –ù–ï –ù–ê–ô–î–ï–ù–ê")
    
    logger.info("\n‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"\n‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ —Å –æ—à–∏–±–∫–æ–π: {e}")
        sys.exit(1)

