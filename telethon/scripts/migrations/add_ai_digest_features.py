#!/usr/bin/env python3
"""
–ú–∏–≥—Ä–∞—Ü–∏—è: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ AI-—Ñ–∏—á –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤

–î–æ–±–∞–≤–ª—è–µ—Ç:
1. –ü–æ–ª—è –≤ digest_settings –¥–ª—è AI-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
2. –¢–∞–±–ª–∏—Ü—É rag_query_history –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤

–î–∞—Ç–∞: 11 –æ–∫—Ç—è–±—Ä—è 2025
"""

import sys
import os
import logging
from datetime import datetime
from sqlalchemy import create_engine, text, inspect

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from database import SessionLocal, engine
from models import Base, User, DigestSettings, RAGQueryHistory

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def backup_database():
    """–°–æ–∑–¥–∞—Ç—å backup –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    db_url = str(engine.url)
    
    if 'sqlite' in db_url:
        import shutil
        db_path = db_url.replace('sqlite:///', '')
        if os.path.exists(db_path):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_path = f"{db_path}.backup_{timestamp}"
            shutil.copy(db_path, backup_path)
            logger.info(f"‚úÖ Backup —Å–æ–∑–¥–∞–Ω: {backup_path}")
            return backup_path
    else:
        logger.info("‚ö†Ô∏è PostgreSQL: —Å–æ–∑–¥–∞–π—Ç–µ backup –≤—Ä—É—á–Ω—É—é —Å –ø–æ–º–æ—â—å—é pg_dump")
        return None


def check_column_exists(engine, table_name: str, column_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏"""
    inspector = inspect(engine)
    columns = [col['name'] for col in inspector.get_columns(table_name)]
    return column_name in columns


def check_table_exists(engine, table_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã"""
    inspector = inspect(engine)
    return table_name in inspector.get_table_names()


def add_ai_digest_columns(engine):
    """–î–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è AI-–¥–∞–π–¥–∂–µ—Å—Ç–∞ –≤ digest_settings"""
    
    columns_to_add = [
        ("ai_summarize", "BOOLEAN DEFAULT 0", "BOOLEAN DEFAULT FALSE"),
        ("preferred_topics", "TEXT", "JSON"),
        ("summary_style", "VARCHAR DEFAULT 'concise'", "VARCHAR DEFAULT 'concise'"),
        ("topics_limit", "INTEGER DEFAULT 5", "INTEGER DEFAULT 5")
    ]
    
    db_url = str(engine.url)
    is_postgres = db_url.startswith('postgresql')
    
    with engine.connect() as conn:
        for col_name, sqlite_type, postgres_type in columns_to_add:
            if check_column_exists(engine, 'digest_settings', col_name):
                logger.info(f"‚è≠Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ digest_settings.{col_name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                continue
            
            col_type = postgres_type if is_postgres else sqlite_type
            sql = f"ALTER TABLE digest_settings ADD COLUMN {col_name} {col_type}"
            
            try:
                conn.execute(text(sql))
                conn.commit()
                logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ digest_settings.{col_name}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏ {col_name}: {e}")
                raise


def create_rag_query_history_table(engine):
    """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É rag_query_history"""
    
    if check_table_exists(engine, 'rag_query_history'):
        logger.info("‚è≠Ô∏è  –¢–∞–±–ª–∏—Ü–∞ rag_query_history —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    # SQL –¥–ª—è SQLite
    sqlite_sql = """
    CREATE TABLE rag_query_history (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER NOT NULL,
        query TEXT NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        extracted_topics TEXT,
        FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
    );
    
    CREATE INDEX ix_rag_query_history_user_id ON rag_query_history(user_id);
    CREATE INDEX ix_rag_query_history_created_at ON rag_query_history(created_at);
    """
    
    # SQL –¥–ª—è PostgreSQL
    postgres_sql = """
    CREATE TABLE rag_query_history (
        id SERIAL PRIMARY KEY,
        user_id INTEGER NOT NULL,
        query TEXT NOT NULL,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        extracted_topics JSON,
        FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
    );
    
    CREATE INDEX ix_rag_query_history_user_id ON rag_query_history(user_id);
    CREATE INDEX ix_rag_query_history_created_at ON rag_query_history(created_at);
    """
    
    db_url = str(engine.url)
    is_postgres = db_url.startswith('postgresql')
    
    sql = postgres_sql if is_postgres else sqlite_sql
    
    try:
        with engine.connect() as conn:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
            for statement in sql.strip().split(';'):
                statement = statement.strip()
                if statement:
                    conn.execute(text(statement))
            conn.commit()
        logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ rag_query_history —Å–æ–∑–¥–∞–Ω–∞")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã rag_query_history: {e}")
        raise


def verify_migration(engine):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏"""
    logger.info("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
    required_columns = ['ai_summarize', 'preferred_topics', 'summary_style', 'topics_limit']
    for col in required_columns:
        exists = check_column_exists(engine, 'digest_settings', col)
        status = "‚úÖ" if exists else "‚ùå"
        logger.info(f"{status} digest_settings.{col}: {'—Å—É—â–µ—Å—Ç–≤—É–µ—Ç' if exists else '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü—ã
    table_exists = check_table_exists(engine, 'rag_query_history')
    status = "‚úÖ" if table_exists else "‚ùå"
    logger.info(f"{status} rag_query_history: {'—Å—É—â–µ—Å—Ç–≤—É–µ—Ç' if table_exists else '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
    
    return all([
        check_column_exists(engine, 'digest_settings', col) 
        for col in required_columns
    ]) and table_exists


def main():
    """–ó–∞–ø—É—Å–∫ –º–∏–≥—Ä–∞—Ü–∏–∏"""
    logger.info("="*60)
    logger.info("üöÄ –ú–∏–≥—Ä–∞—Ü–∏—è: AI Digest Features")
    logger.info("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ .env
    if not os.path.exists('.env'):
        logger.warning("‚ö†Ô∏è –§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
    
    # Backup
    logger.info("\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ backup...")
    backup_path = backup_database()
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏
    try:
        logger.info("\nüîÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ AI –∫–æ–ª–æ–Ω–æ–∫ –≤ digest_settings...")
        add_ai_digest_columns(engine)
        
        logger.info("\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã rag_query_history...")
        create_rag_query_history_table(engine)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞
        if verify_migration(engine):
            logger.info("\n‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞!")
            logger.info("\n–¢–µ–ø–µ—Ä—å –¥–æ—Å—Ç—É–ø–Ω—ã:")
            logger.info("  ‚Ä¢ AI-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤")
            logger.info("  ‚Ä¢ –ò—Å—Ç–æ—Ä–∏—è RAG-–∑–∞–ø—Ä–æ—Å–æ–≤")
            logger.info("  ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            logger.info("\n–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:")
            logger.info("  PUT /rag/digest/settings/{user_id}")
            logger.info("  {")
            logger.info('    "ai_summarize": true,')
            logger.info('    "preferred_topics": ["–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã", "–∞–≤—Ç–æ", "—Ñ–∏–Ω–∞–Ω—Å—ã"],')
            logger.info('    "summary_style": "concise",')
            logger.info('    "topics_limit": 5')
            logger.info("  }")
        else:
            logger.error("\n‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏!")
            return 1
            
    except Exception as e:
        logger.error(f"\n‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
        if backup_path:
            logger.info(f"üíæ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏–∑ backup: {backup_path}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

