"""
Unified Retention Service
–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º digest frequency –∏ best practices

Features:
- Smart retention (—É—á–µ—Ç digest frequency)
- Channel orphan cleanup (–Ω–µ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤)
- Dry run mode
- Sync cleanup: PostgreSQL ‚Üí Neo4j ‚Üí Qdrant
- Context7 best practices (PostgreSQL partitioning)

Best practices (from Context7):
- PostgreSQL: batch DELETE + VACUUM OR –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
- Neo4j: DETACH DELETE —Å batch iterations (apoc.periodic.iterate)
- Qdrant: delete by filter (posted_at < cutoff_date)
- Sequential cleanup: PostgreSQL ‚Üí Neo4j ‚Üí Qdrant
"""

import logging
import os
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, List, Optional

# Imports
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from database import SessionLocal
from models import Post, User, Channel, DigestSettings, user_channel
from rag_service.metrics import record_cleanup

logger = logging.getLogger(__name__)


class UnifiedRetentionService:
    """
    –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    
    –õ–æ–≥–∏–∫–∞ retention:
    retention = MAX(
        90 days,  # –ë–∞–∑–æ–≤—ã–π –º–∏–Ω–∏–º—É–º (3 –º–µ—Å—è—Ü–∞)
        digest_period * 2,  # –ó–∞–ø–∞—Å –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤
        user.retention_days  # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
    )
    
    Edge cases:
    - –û—Ç–ø–∏—Å–∫–∞ –æ—Ç –∫–∞–Ω–∞–ª–∞ ‚Üí orphaned channels cleanup
    - –†–∞–∑–Ω—ã–µ digest frequency ‚Üí maximum period
    - –ù–µ–¥–∞–≤–Ω–∏–µ –ø–æ—Å—Ç—ã vs —Å—Ç–∞—Ä—ã–µ ‚Üí –º–∏–Ω–∏–º—É–º 90 –¥–Ω–µ–π –¥–ª—è RAG
    """
    
    def __init__(self, base_retention_days: int = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è unified retention service
        
        Args:
            base_retention_days: –ë–∞–∑–æ–≤—ã–π –º–∏–Ω–∏–º—É–º retention (default: 90 –¥–Ω–µ–π)
        """
        if base_retention_days is None:
            base_retention_days = int(os.getenv("DATA_RETENTION_DAYS", "90"))
        
        self.base_retention_days = base_retention_days
        self.min_retention_days = 90  # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –º–∏–Ω–∏–º—É–º –¥–ª—è RAG/search
        self.max_retention_days = 3650  # –ú–∞–∫—Å–∏–º—É–º (10 –ª–µ—Ç)
        
        logger.info(f"üóëÔ∏è UnifiedRetentionService initialized (base: {base_retention_days} days)")
        logger.info(f"   Min retention: {self.min_retention_days} days (for RAG/search)")
    
    async def calculate_retention_period(self, user_id: int) -> int:
        """
        –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø–µ—Ä–∏–æ–¥ retention –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        –õ–æ–≥–∏–∫–∞:
        1. –ë–∞–∑–æ–≤—ã–π –º–∏–Ω–∏–º—É–º: 90 –¥–Ω–µ–π (–¥–ª—è RAG/search)
        2. Digest frequency: period * 2 (–∑–∞–ø–∞—Å –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤)
        3. User retention_days: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
        4. Maximum –∏–∑ –≤—Å–µ—Ö
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π retention
        """
        db = SessionLocal()
        try:
            # 1. –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user = db.query(User).filter(User.id == user_id).first()
            if not user:
                logger.warning(f"‚ö†Ô∏è User {user_id} not found, using base retention")
                return self.base_retention_days
            
            # 2. –ë–∞–∑–æ–≤—ã–π –º–∏–Ω–∏–º—É–º (–¥–ª—è RAG/search)
            base_retention = self.min_retention_days
            
            # 3. –ü–æ–ª—É—á–∏—Ç—å digest settings
            digest_settings = db.query(DigestSettings).filter(
                DigestSettings.user_id == user_id
            ).first()
            
            # 4. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å frequency –≤ –¥–Ω–∏
            if digest_settings and digest_settings.enabled:
                if digest_settings.frequency == "daily":
                    digest_period = 1
                elif digest_settings.frequency == "weekly":
                    digest_period = 7
                elif digest_settings.frequency == "monthly":
                    digest_period = 30
                else:
                    digest_period = 7  # Default weekly
                
                # –ó–∞–ø–∞—Å –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: period * 2
                digest_retention = digest_period * 2
                logger.debug(f"üìä User {user_id}: digest {digest_settings.frequency} ‚Üí {digest_retention} days")
            else:
                digest_retention = 14  # Default: 2 weeks for weekly digest
                logger.debug(f"üìä User {user_id}: no digest settings ‚Üí {digest_retention} days")
            
            # 5. User retention_days
            user_retention = user.retention_days or 30
            
            # 6. Maximum
            calculated_retention = max(base_retention, digest_retention, user_retention)
            
            # 7. –í–∞–ª–∏–¥–∞—Ü–∏—è
            if calculated_retention < self.min_retention_days:
                logger.warning(f"‚ö†Ô∏è User {user_id}: calculated {calculated_retention} < min {self.min_retention_days}")
                calculated_retention = self.min_retention_days
            
            if calculated_retention > self.max_retention_days:
                logger.warning(f"‚ö†Ô∏è User {user_id}: calculated {calculated_retention} > max {self.max_retention_days}")
                calculated_retention = self.max_retention_days
            
            logger.debug(f"‚úÖ User {user_id}: retention = max({base_retention}, {digest_retention}, {user_retention}) = {calculated_retention}")
            
            return calculated_retention
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating retention for user {user_id}: {e}")
            return self.base_retention_days
        finally:
            db.close()
    
    async def cleanup_orphaned_channels(self, dry_run: bool = False) -> int:
        """
        –û—á–∏—Å—Ç–∫–∞ –∫–∞–Ω–∞–ª–æ–≤ –±–µ–∑ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
        
        –õ–æ–≥–∏–∫–∞:
        - –ö–∞–Ω–∞–ª —Å—á–∏—Ç–∞–µ—Ç—Å—è orphaned –µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫
        - –£–¥–∞–ª—è—é—Ç—Å—è –ø–æ—Å—Ç—ã –∫–∞–Ω–∞–ª–∞ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
        - –°–∞–º –∫–∞–Ω–∞–ª –æ—Å—Ç–∞–µ—Ç—Å—è (–¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
        
        Args:
            dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–¥—Å—á–µ—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        logger.info(f"üßπ Cleanup orphaned channels (dry_run={dry_run})")
        
        db = SessionLocal()
        try:
            # –ù–∞–π—Ç–∏ –∫–∞–Ω–∞–ª—ã –±–µ–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫
            orphaned_channels = db.query(Channel).filter(
                ~Channel.id.in_(
                    db.query(user_channel.c.channel_id).filter(
                        user_channel.c.is_active == True
                    )
                )
            ).all()
            
            if not orphaned_channels:
                logger.info("üì≠ No orphaned channels found")
                return 0
            
            logger.info(f"üìä Found {len(orphaned_channels)} orphaned channels")
            
            cutoff = datetime.now(timezone.utc) - timedelta(days=30)
            total_deleted = 0
            
            for channel in orphaned_channels:
                try:
                    # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–æ—Å—Ç—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                    posts_query = db.query(Post).filter(
                        Post.channel_id == channel.id,
                        Post.posted_at < cutoff
                    )
                    count = posts_query.count()
                    
                    if count > 0:
                        logger.info(f"üìä Channel @{channel.channel_username}: {count} posts to delete")
                        
                        if not dry_run:
                            # –£–¥–∞–ª–∏—Ç—å –ø–æ—Å—Ç—ã
                            deleted = posts_query.delete(synchronize_session=False)
                            db.commit()
                            total_deleted += deleted
                            logger.info(f"‚úÖ Channel @{channel.channel_username}: deleted {deleted} posts")
                        else:
                            total_deleted += count
                    
                except Exception as e:
                    logger.error(f"‚ùå Error cleaning channel @{channel.channel_username}: {e}")
                    db.rollback()
                    continue
            
            logger.info(f"‚úÖ Orphaned channels cleanup: {total_deleted} posts {'would be' if dry_run else ''} deleted")
            return total_deleted
            
        except Exception as e:
            logger.error(f"‚ùå Error in orphaned channels cleanup: {e}")
            db.rollback()
            return 0
        finally:
            db.close()
    
    async def cleanup_user_posts(self, user_id: int, dry_run: bool = False) -> Dict[str, Any]:
        """
        –û—á–∏—Å—Ç–∫–∞ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–¥—Å—á–µ—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        """
        try:
            # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å retention period
            retention_days = await self.calculate_retention_period(user_id)
            cutoff_date = datetime.now(timezone.utc) - timedelta(days=retention_days)
            
            logger.info(f"üìä User {user_id}: retention={retention_days} days, cutoff={cutoff_date.isoformat()}")
            
            db = SessionLocal()
            try:
                # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–æ—Å—Ç—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                posts_query = db.query(Post).filter(
                    Post.user_id == user_id,
                    Post.posted_at < cutoff_date
                )
                count = posts_query.count()
                
                if count == 0:
                    return {
                        "user_id": user_id,
                        "retention_days": retention_days,
                        "cutoff_date": cutoff_date.isoformat(),
                        "posts_deleted": 0,
                        "dry_run": dry_run
                    }
                
                logger.info(f"üìä User {user_id}: {count} posts to delete")
                
                if not dry_run:
                    # –£–¥–∞–ª–∏—Ç—å –ø–æ—Å—Ç—ã
                    deleted = posts_query.delete(synchronize_session=False)
                    db.commit()
                    logger.info(f"‚úÖ User {user_id}: deleted {deleted} posts")
                else:
                    deleted = count
                
                return {
                    "user_id": user_id,
                    "retention_days": retention_days,
                    "cutoff_date": cutoff_date.isoformat(),
                    "posts_deleted": deleted,
                    "dry_run": dry_run
                }
                
            except Exception as e:
                logger.error(f"‚ùå Error cleaning posts for user {user_id}: {e}")
                db.rollback()
                return {
                    "user_id": user_id,
                    "error": str(e),
                    "dry_run": dry_run
                }
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Error in cleanup_user_posts for user {user_id}: {e}")
            return {
                "user_id": user_id,
                "error": str(e),
                "dry_run": dry_run
            }
    
    async def cleanup_all_users(self, dry_run: bool = False) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ—á–∏—Å—Ç–∫–∏ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        
        Args:
            dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–¥—Å—á–µ—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
            
        Returns:
            –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        """
        logger.info(f"üßπ Starting unified cleanup (dry_run={dry_run})")
        
        db = SessionLocal()
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            users = db.query(User).filter(User.is_active == True).all()
            
            if not users:
                logger.info("üì≠ No active users found")
                return {
                    "status": "success",
                    "users_processed": 0,
                    "total_posts_deleted": 0,
                    "dry_run": dry_run,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
            
            logger.info(f"üìä Processing {len(users)} active users")
            
            total_posts_deleted = 0
            users_processed = 0
            user_stats = []
            errors = []
            
            for user in users:
                try:
                    result = await self.cleanup_user_posts(user.id, dry_run)
                    users_processed += 1
                    
                    if "error" in result:
                        errors.append(f"User {user.id}: {result['error']}")
                    else:
                        posts_deleted = result.get("posts_deleted", 0)
                        total_posts_deleted += posts_deleted
                        
                        if posts_deleted > 0:
                            user_stats.append({
                                "user_id": user.id,
                                "telegram_id": user.telegram_id,
                                "retention_days": result.get("retention_days"),
                                "posts_deleted": posts_deleted
                            })
                            logger.info(f"‚úÖ User {user.telegram_id}: {posts_deleted} posts {'would be' if dry_run else ''} deleted")
                
                except Exception as e:
                    logger.error(f"‚ùå Error processing user {user.id}: {e}")
                    errors.append(f"User {user.id}: {str(e)}")
                    continue
            
            # Cleanup orphaned channels
            try:
                orphaned_deleted = await self.cleanup_orphaned_channels(dry_run)
                total_posts_deleted += orphaned_deleted
            except Exception as e:
                logger.error(f"‚ùå Error in orphaned channels cleanup: {e}")
                errors.append(f"Orphaned channels: {str(e)}")
            
            logger.info(f"‚úÖ Unified cleanup complete: {total_posts_deleted} posts {'would be' if dry_run else ''} deleted")
            
            return {
                "status": "success",
                "users_processed": users_processed,
                "total_posts_deleted": total_posts_deleted,
                "user_stats": user_stats,
                "errors": errors,
                "dry_run": dry_run,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Critical error in unified cleanup: {e}")
            return {
                "status": "error",
                "error": str(e),
                "dry_run": dry_run,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        finally:
            db.close()
    
    async def get_retention_stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ retention –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ retention
        """
        logger.info("üìä Getting retention statistics")
        
        db = SessionLocal()
        try:
            users = db.query(User).filter(User.is_active == True).all()
            
            stats = {
                "total_users": len(users),
                "retention_stats": [],
                "summary": {
                    "min_retention": self.min_retention_days,
                    "max_retention": self.max_retention_days,
                    "base_retention": self.base_retention_days
                }
            }
            
            for user in users:
                try:
                    retention_days = await self.calculate_retention_period(user.id)
                    
                    # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–æ—Å—Ç—ã
                    cutoff_date = datetime.now(timezone.utc) - timedelta(days=retention_days)
                    posts_count = db.query(Post).filter(
                        Post.user_id == user.id,
                        Post.posted_at < cutoff_date
                    ).count()
                    
                    stats["retention_stats"].append({
                        "user_id": user.id,
                        "telegram_id": user.telegram_id,
                        "retention_days": retention_days,
                        "posts_to_delete": posts_count,
                        "cutoff_date": cutoff_date.isoformat()
                    })
                    
                except Exception as e:
                    logger.error(f"‚ùå Error getting stats for user {user.id}: {e}")
                    continue
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Error getting retention stats: {e}")
            return {"error": str(e)}
        finally:
            db.close()


# Global instance
unified_retention_service = UnifiedRetentionService()
